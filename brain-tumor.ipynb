{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4d6e7e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-29T14:21:48.835037Z",
     "iopub.status.busy": "2025-05-29T14:21:48.834368Z",
     "iopub.status.idle": "2025-05-29T14:21:59.170800Z",
     "shell.execute_reply": "2025-05-29T14:21:59.170223Z"
    },
    "papermill": {
     "duration": 10.342015,
     "end_time": "2025-05-29T14:21:59.172111",
     "exception": false,
     "start_time": "2025-05-29T14:21:48.830096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading of the necessary libraries\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d44a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my ID: 5b41ba5a-9fd4-4049-a2c8-2a92a73f1450\n"
     ]
    }
   ],
   "source": [
    "#will give your pc a unique id stored in config.txt, please do not remove this file once created\n",
    "from library.get_id import get_or_create_unique_id\n",
    "\n",
    "my_id = get_or_create_unique_id()\n",
    "print(\"my ID:\", my_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61f81b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:21:59.194929Z",
     "iopub.status.busy": "2025-05-29T14:21:59.194729Z",
     "iopub.status.idle": "2025-05-29T14:21:59.283788Z",
     "shell.execute_reply": "2025-05-29T14:21:59.283222Z"
    },
    "papermill": {
     "duration": 0.093111,
     "end_time": "2025-05-29T14:21:59.284811",
     "exception": false,
     "start_time": "2025-05-29T14:21:59.191700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DirectML device\n"
     ]
    }
   ],
   "source": [
    "#will try and get the most appropriate device for training\n",
    "from library.get_device import get_device\n",
    "\n",
    "device = get_device(no_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48251b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:21:59.291015Z",
     "iopub.status.busy": "2025-05-29T14:21:59.290805Z",
     "iopub.status.idle": "2025-05-29T14:21:59.294727Z",
     "shell.execute_reply": "2025-05-29T14:21:59.294216Z"
    },
    "papermill": {
     "duration": 0.00811,
     "end_time": "2025-05-29T14:21:59.295755",
     "exception": false,
     "start_time": "2025-05-29T14:21:59.287645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data preprocessing & augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444d92bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:21:59.301608Z",
     "iopub.status.busy": "2025-05-29T14:21:59.301380Z",
     "iopub.status.idle": "2025-05-29T14:21:59.304780Z",
     "shell.execute_reply": "2025-05-29T14:21:59.304299Z"
    },
    "papermill": {
     "duration": 0.007274,
     "end_time": "2025-05-29T14:21:59.305673",
     "exception": false,
     "start_time": "2025-05-29T14:21:59.298399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data preprocessing & augmentation for testing\n",
    "test_transform =transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad1b905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:21:59.311356Z",
     "iopub.status.busy": "2025-05-29T14:21:59.311133Z",
     "iopub.status.idle": "2025-05-29T14:22:03.697261Z",
     "shell.execute_reply": "2025-05-29T14:22:03.696714Z"
    },
    "papermill": {
     "duration": 4.390314,
     "end_time": "2025-05-29T14:22:03.698552",
     "exception": false,
     "start_time": "2025-05-29T14:21:59.308238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading of the dataset\n",
    "data_dir = \"./kaggle/input/brain-tumor/4 classes\"\n",
    "dataset = ImageFolder(root=data_dir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dd269f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:22:03.704872Z",
     "iopub.status.busy": "2025-05-29T14:22:03.704661Z",
     "iopub.status.idle": "2025-05-29T14:22:03.710396Z",
     "shell.execute_reply": "2025-05-29T14:22:03.709928Z"
    },
    "papermill": {
     "duration": 0.009835,
     "end_time": "2025-05-29T14:22:03.711355",
     "exception": false,
     "start_time": "2025-05-29T14:22:03.701520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset (70-15-15 split)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce8791d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:22:03.717380Z",
     "iopub.status.busy": "2025-05-29T14:22:03.717171Z",
     "iopub.status.idle": "2025-05-29T14:22:03.720387Z",
     "shell.execute_reply": "2025-05-29T14:22:03.719724Z"
    },
    "papermill": {
     "duration": 0.007478,
     "end_time": "2025-05-29T14:22:03.721455",
     "exception": false,
     "start_time": "2025-05-29T14:22:03.713977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assign the preprocessing to the different sets\n",
    "val_dataset.dataset.tranform = test_transform\n",
    "test_dataset.dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cebdbea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:22:03.737520Z",
     "iopub.status.busy": "2025-05-29T14:22:03.737352Z",
     "iopub.status.idle": "2025-05-29T14:22:03.742518Z",
     "shell.execute_reply": "2025-05-29T14:22:03.742033Z"
    },
    "papermill": {
     "duration": 0.009239,
     "end_time": "2025-05-29T14:22:03.743590",
     "exception": false,
     "start_time": "2025-05-29T14:22:03.734351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "class BrainTumorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4, dropout=0.5):\n",
    "        super(BrainTumorCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb01007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the hyperparameters:\n",
    "class HyperParameters():\n",
    "    def __init__(self,\n",
    "                 learning_rate = 0.001,\n",
    "                 batch_size = 32,\n",
    "                 epochs = 10,\n",
    "                 dropout = 0.5,\n",
    "                 optimizer_type = \"adam\"\n",
    "                 ) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.dropout = dropout\n",
    "        self.optimizer_type = optimizer_type\n",
    "        \n",
    "    def build_model(self, device):\n",
    "        return BrainTumorCNN(num_classes=4, dropout=self.dropout).to(device)\n",
    "\n",
    "    def build_optimizer(self, model):\n",
    "        if self.optimizer_type == \"adam\":\n",
    "            return optim.Adam(model.parameters(), lr=self.learning_rate)\n",
    "        elif self.optimizer_type == \"sgd\":\n",
    "            return optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer type: '{self.optimizer_type}'. \"\n",
    "                         f\"Supported types: 'adam', 'sgd'.\")\n",
    "\n",
    "    def build_criterion(self):\n",
    "        return nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4243423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model, criterion, optimizer:\n",
    "hyperParameters = HyperParameters()\n",
    "model = hyperParameters.build_model(device)\n",
    "criterion = hyperParameters.build_criterion()\n",
    "optimizer = hyperParameters.build_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d18d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:22:03.727412Z",
     "iopub.status.busy": "2025-05-29T14:22:03.726973Z",
     "iopub.status.idle": "2025-05-29T14:22:03.730695Z",
     "shell.execute_reply": "2025-05-29T14:22:03.730180Z"
    },
    "papermill": {
     "duration": 0.007606,
     "end_time": "2025-05-29T14:22:03.731668",
     "exception": false,
     "start_time": "2025-05-29T14:22:03.724062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assigns the loaders to the sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyperParameters.batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=hyperParameters.batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyperParameters.batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05185350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:22:04.446958Z",
     "iopub.status.busy": "2025-05-29T14:22:04.446676Z",
     "iopub.status.idle": "2025-05-29T14:24:21.140093Z",
     "shell.execute_reply": "2025-05-29T14:24:21.139088Z"
    },
    "papermill": {
     "duration": 136.697931,
     "end_time": "2025-05-29T14:24:21.141672",
     "exception": false,
     "start_time": "2025-05-29T14:22:04.443741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rouer\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:534: UserWarning: The operator 'aten::lerp.Scalar_out' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at C:\\__w\\1\\s\\pytorch-directml-plugin\\torch_directml\\csrc\\dml\\dml_cpu_fallback.cpp:17.)\n",
      "  torch._foreach_lerp_(device_exp_avgs, device_grads, 1 - beta1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.6757, Train Acc: 44.90%, Val Loss: 0.9575, Val Acc: 59.70%, Time: 19.87s\n",
      "Epoch [2/10], Train Loss: 0.8456, Train Acc: 66.77%, Val Loss: 0.6678, Val Acc: 75.22%, Time: 19.40s\n",
      "Epoch [3/10], Train Loss: 0.5576, Train Acc: 78.73%, Val Loss: 0.5728, Val Acc: 76.72%, Time: 18.99s\n",
      "Epoch [4/10], Train Loss: 0.4123, Train Acc: 85.37%, Val Loss: 0.5527, Val Acc: 81.03%, Time: 17.53s\n",
      "Epoch [5/10], Train Loss: 0.2906, Train Acc: 89.94%, Val Loss: 0.5829, Val Acc: 80.39%, Time: 19.38s\n",
      "Epoch [6/10], Train Loss: 0.2186, Train Acc: 92.16%, Val Loss: 0.6018, Val Acc: 82.54%, Time: 19.35s\n",
      "Epoch [7/10], Train Loss: 0.1513, Train Acc: 94.69%, Val Loss: 0.6736, Val Acc: 81.90%, Time: 19.55s\n",
      "Epoch [8/10], Train Loss: 0.1141, Train Acc: 96.17%, Val Loss: 0.6546, Val Acc: 84.48%, Time: 19.48s\n",
      "Epoch [9/10], Train Loss: 0.0870, Train Acc: 97.19%, Val Loss: 0.6234, Val Acc: 84.05%, Time: 19.37s\n",
      "Epoch [10/10], Train Loss: 0.0483, Train Acc: 98.34%, Val Loss: 0.7572, Val Acc: 81.68%, Time: 19.51s\n"
     ]
    }
   ],
   "source": [
    "#resets the losses & accuracies\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "timings =  []\n",
    "\n",
    "#generates a unique id for the run\n",
    "from library.get_id import get_unique_run_id\n",
    "run_id = get_unique_run_id()\n",
    "\n",
    "#trains & measures the model\n",
    "for epoch in range(hyperParameters.epochs):\n",
    "    start_time = time.time()  # start timer\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    timings.append(epoch_time)\n",
    "    print(f\"Epoch [{epoch+1}/{hyperParameters.epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Time: {epoch_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf425b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data: storing the hyperparameters's values\n",
    "results = {\n",
    "        'computer_id': my_id,\n",
    "        'learning_rate': hyperParameters.learning_rate,\n",
    "        'batch_size': hyperParameters.batch_size,\n",
    "        'epochs': hyperParameters.epochs,\n",
    "        'dropout': hyperParameters.dropout,\n",
    "        'optimizer_type': hyperParameters.optimizer_type,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rouer\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:534: UserWarning: The operator 'aten::lerp.Scalar_out' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at C:\\__w\\1\\s\\pytorch-directml-plugin\\torch_directml\\csrc\\dml\\dml_cpu_fallback.cpp:17.)\n",
      "  torch._foreach_lerp_(device_exp_avgs, device_grads, 1 - beta1)\n"
     ]
    }
   ],
   "source": [
    "#preparing the data: training of the model & storing results\n",
    "from library.training import train_model\n",
    "\n",
    "results = results | train_model(model, train_loader, val_loader, criterion, optimizer, device, hyperParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70560b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:24:21.150030Z",
     "iopub.status.busy": "2025-05-29T14:24:21.149758Z",
     "iopub.status.idle": "2025-05-29T14:24:22.886153Z",
     "shell.execute_reply": "2025-05-29T14:24:22.885345Z"
    },
    "papermill": {
     "duration": 1.742084,
     "end_time": "2025-05-29T14:24:22.887462",
     "exception": false,
     "start_time": "2025-05-29T14:24:21.145378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preparing the data: testing of the model & storing results\n",
    "from library.evaluation import evaluate\n",
    "\n",
    "results = results | evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac05de3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_results.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from library.save_results import save_training_results_to_csv\n",
    "\n",
    "save_training_results_to_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcee9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:24:22.895411Z",
     "iopub.status.busy": "2025-05-29T14:24:22.895152Z",
     "iopub.status.idle": "2025-05-29T14:24:22.898449Z",
     "shell.execute_reply": "2025-05-29T14:24:22.897905Z"
    },
    "papermill": {
     "duration": 0.00836,
     "end_time": "2025-05-29T14:24:22.899389",
     "exception": false,
     "start_time": "2025-05-29T14:24:22.891029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "# torch.save(model.state_dict(), \"brain_tumor.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a02ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:24:22.906855Z",
     "iopub.status.busy": "2025-05-29T14:24:22.906678Z",
     "iopub.status.idle": "2025-05-29T14:24:23.354564Z",
     "shell.execute_reply": "2025-05-29T14:24:23.353852Z"
    },
    "papermill": {
     "duration": 0.453513,
     "end_time": "2025-05-29T14:24:23.356218",
     "exception": false,
     "start_time": "2025-05-29T14:24:22.902705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Training and Validation Metrics\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7538430,
     "sourceId": 11985632,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 162.564121,
   "end_time": "2025-05-29T14:24:26.664763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-29T14:21:44.100642",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
